
{
  "documentation": {
    "tokens": {
      "token": "the token (word) to train, given exactly as it appears in tokens",
      "initializer": "starting point for the embedding. make it close to the intended meaning to kick-start training. should be shorter (in tokens) than the vector_length.",
      "vector_length": "length of the embedding (default 1). use more if you have more images and/or if what you want to train is complex."
    },
    "example": "the example below trains `hat*`, `dancing shoes` and `cane` as custom tokens, if you have training data where the captions include those tokens."
  },
  "tokens": [
    { "token": "hat*", "initializer": "a man's hat", "vector_length": 8 },
    { "token": "dancing shoes", "initializer": "shoes" },
    { "token": "cane", "initializer": "cane" }
  ]
}
